{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data Files from Google Earth Engine and NASA \n",
    "This notebook imports .tif files exported from google earth engine, and the GFWD (for the month of December) from NASA's Archives. It scales data to the same dimensions, assigns lat and lon coordinates, and exports the consolidated dataset as a pandas dataframe parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Anaconda3\\envs\\merging\\lib\\site-packages\\pysal\\explore\\segregation\\network\\network.py:16: UserWarning: You need pandana and urbanaccess to work with segregation's network module\n",
      "You can install them with  `pip install urbanaccess pandana` or `conda install -c udst pandana urbanaccess`\n",
      "  \"You need pandana and urbanaccess to work with segregation's network module\\n\"\n",
      "C:\\Users\\allis\\Anaconda3\\envs\\merging\\lib\\site-packages\\pysal\\model\\spvcm\\abstracts.py:10: UserWarning: The `dill` module is required to use the sqlite backend fully.\n",
      "  from .sqlite import head_to_sql, start_sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from affine import Affine\n",
    "import xarray as xr\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import matplotlib.pyplot as plt\n",
    "import georasters as gr\n",
    "import geopandas\n",
    "from rastertodataframe import raster_to_dataframe\n",
    "import os\n",
    "from glob import glob\n",
    "from rasterio.plot import plotting_extent\n",
    "import geopandas as gpd\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "%run ../pyfiles/data_cleaning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data paths associated with time period to paths. Then run notebook to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "# CRS.from_epsg(4326)\n",
    "fire = '../../finalproj_data/data_dec/fire_final.tif' #float32\n",
    "air = '../../finalproj_data/data_dec/air.tif' #float32\n",
    "precip = '../../finalproj_data/data_dec/precip_final.tif' #float32\n",
    "veg = '../../finalproj_data/data_dec/veg.tif' #float32\n",
    "burn = '../../finalproj_data/data_dec/burned_nov.tif' #float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this code to check datatype of bands in each file\n",
    "# {i: dtype for i, dtype in zip(veg.indexes, veg.dtypes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file into rasterio\n",
    "fire = rio.open(fire)\n",
    "air = rio.open(air)\n",
    "precip = rio.open(precip)\n",
    "veg = rio.open(veg)\n",
    "burned = rio.open(burn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire.meta #count shows the number of bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shapes of all the bands from different datasets\n",
    "fire_shape = list(fire.read(1).shape)\n",
    "veg_shape = list(veg.read(1).shape)\n",
    "precip_shape = list(precip.read(1).shape)\n",
    "air_shape = list(air.read(1).shape)\n",
    "burned_shape = list(burned.read(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([917, 1128], [917, 1128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_shape, burned_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info from google earth engine\n",
    "# scale factors are calculated as a proportion of the dimensions of the fire dataset\n",
    "\n",
    "fire_bands = ['FireMask', 'MaxFRP', 'QA', 'sample']\n",
    "a, b = fire_shape[0], fire_shape[1]\n",
    "\n",
    "# Vegetation bands were not deemed important features after RF classification - dropped this dataset. \n",
    "# veg_bands = ['EVI', 'EVI2', 'NVDI','NIR_reflectance', 'SWIR1_reflectance', \n",
    "#              'SWIR2_reflectance', 'SWIR3_reflectance', 'VI_Quality', 'blue_reflectance',\n",
    "#             'composite_day_of_the_year', 'green_reflectance', 'pixel_reliability',\n",
    "#             'red_reflectance','relative_azimuth_angle','sun_zenith_angle','view_zenith_angle']\n",
    "# veg_scale_factors = (a/veg_shape[0], b/veg_shape[1])\n",
    "\n",
    "precip_bands = ['gaugeQualityInfo', 'hourlyPrecipRate', 'hourlyPrecipRateGC', 'observationTimeFlag', 'satelliteInfoFlag']\n",
    "precip_scale_factors = (a/precip_shape[0], b/precip_shape[1])\n",
    "\n",
    "air_bands = ['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg','ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg',\n",
    "'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', \n",
    "'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst',\n",
    "'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst',\n",
    "'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst',\n",
    "'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst']\n",
    "air_scale_factors = (a/air_shape[0], b/air_shape[1])\n",
    "\n",
    "burned_bands = ['BurnDate', 'Uncertainty', 'QA', 'FirstDay', 'LastDay']\n",
    "burned_scale_factors = (a/burned_shape[0], b/burned_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bands as separate arrays and scale to appropriate dimensions\n",
    "FireMask = fire.read(1)\n",
    "MaxFRP = fire.read(2)\n",
    "\n",
    "# EVI = scale_variable(veg.read(1), veg_scale_factors)\n",
    "# EVI2 = scale_variable(veg.read(2), veg_scale_factors)\n",
    "# NVDI = scale_variable(veg.read(3), veg_scale_factors)\n",
    "# NIR_reflectance = scale_variable(veg.read(4), veg_scale_factors)\n",
    "# SWIR1_reflectance = scale_variable(veg.read(5), veg_scale_factors)\n",
    "# SWIR2_reflectance = scale_variable(veg.read(6), veg_scale_factors)\n",
    "# SWIR3_reflectance = scale_variable(veg.read(7), veg_scale_factors)\n",
    "# VI_Quality = scale_variable(veg.read(8), veg_scale_factors)\n",
    "# blue_reflectance = scale_variable(veg.read(9), veg_scale_factors)\n",
    "# composite_day_of_the_year = scale_variable(veg.read(10), veg_scale_factors)\n",
    "# green_reflectance = scale_variable(veg.read(11), veg_scale_factors)\n",
    "# pixel_reliability = scale_variable(veg.read(12), veg_scale_factors)\n",
    "# red_reflectance = scale_variable(veg.read(13), veg_scale_factors)\n",
    "# relative_azimuth_angle = scale_variable(veg.read(14), veg_scale_factors)\n",
    "# sun_zenith_angle = scale_variable(veg.read(15), veg_scale_factors)\n",
    "# view_zenith_angle = scale_variable(veg.read(16), veg_scale_factors)\n",
    "\n",
    "gaugeQualityInfo = scale_variable(precip.read(1), precip_scale_factors)\n",
    "hourlyPrecipRate = scale_variable(precip.read(2), precip_scale_factors)\n",
    "hourlyPrecipRateGC = scale_variable(precip.read(3), precip_scale_factors)\n",
    "observationTimeFlag = scale_variable(precip.read(4), precip_scale_factors)\n",
    "satelliteInfoFlag = scale_variable(precip.read(5), precip_scale_factors)\n",
    "\n",
    "Albedo_inst = scale_variable(air.read(1), air_scale_factors)\n",
    "AvgSurfT_inst = scale_variable(air.read(2), air_scale_factors)\n",
    "CanopInt_inst = scale_variable(air.read(3), air_scale_factors)\n",
    "ECanop_tavg = scale_variable(air.read(4), air_scale_factors)\n",
    "ESoil_tavg = scale_variable(air.read(5), air_scale_factors)\n",
    "Evap_tavg = scale_variable(air.read(6), air_scale_factors)\n",
    "LWdown_f_tavg = scale_variable(air.read(7), air_scale_factors)\n",
    "Lwnet_tavg = scale_variable(air.read(8), air_scale_factors)\n",
    "PotEvap_tavg = scale_variable(air.read(9), air_scale_factors)\n",
    "Psurf_f_inst = scale_variable(air.read(10), air_scale_factors)\n",
    "Qair_f_inst = scale_variable(air.read(11), air_scale_factors)\n",
    "Qg_tavg = scale_variable(air.read(12), air_scale_factors)\n",
    "Qh_tavg = scale_variable(air.read(13), air_scale_factors)\n",
    "Qle_tavg = scale_variable(air.read(14), air_scale_factors)\n",
    "Qs_acc = scale_variable(air.read(15), air_scale_factors)\n",
    "Qsb_acc = scale_variable(air.read(16), air_scale_factors)\n",
    "Qsm_acc = scale_variable(air.read(17), air_scale_factors)\n",
    "Rainf_f_tavg = scale_variable(air.read(18), air_scale_factors)\n",
    "Rainf_tavg = scale_variable(air.read(19), air_scale_factors)\n",
    "RootMoist_inst = scale_variable(air.read(20), air_scale_factors)\n",
    "SWE_inst = scale_variable(air.read(21), air_scale_factors)\n",
    "SWdown_f_tavg = scale_variable(air.read(22), air_scale_factors)\n",
    "SnowDepth_inst = scale_variable(air.read(23), air_scale_factors)\n",
    "Snowf_tavg = scale_variable(air.read(24), air_scale_factors)\n",
    "SoilMoi0_10cm_inst = scale_variable(air.read(25), air_scale_factors)\n",
    "SoilMoi100_200cm_inst = scale_variable(air.read(26), air_scale_factors)\n",
    "SoilMoi10_40cm_inst = scale_variable(air.read(27), air_scale_factors)\n",
    "SoilMoi40_100cm_inst = scale_variable(air.read(28), air_scale_factors)\n",
    "SoilTMP0_10cm_inst = scale_variable(air.read(29), air_scale_factors)\n",
    "SoilTMP100_200cm_inst = scale_variable(air.read(30), air_scale_factors)\n",
    "SoilTMP10_40cm_inst = scale_variable(air.read(31), air_scale_factors)\n",
    "SoilTMP40_100cm_inst = scale_variable(air.read(32), air_scale_factors)\n",
    "Swnet_tavg = scale_variable(air.read(33), air_scale_factors)\n",
    "Tair_f_inst = scale_variable(air.read(34), air_scale_factors)\n",
    "Tveg_tavg = scale_variable(air.read(35), air_scale_factors)\n",
    "Wind_f_inst = scale_variable(air.read(36), air_scale_factors)\n",
    "\n",
    "BurnDate = scale_variable(burned.read(1), burned_scale_factors)\n",
    "Uncertainty = scale_variable(burned.read(2), burned_scale_factors)\n",
    "QA = scale_variable(burned.read(3), burned_scale_factors)\n",
    "FirstDay = scale_variable(burned.read(4), burned_scale_factors)\n",
    "LastDay = scale_variable(burned.read(5), burned_scale_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allis\\Anaconda3\\envs\\merging\\lib\\site-packages\\xarray\\coding\\variables.py:141: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  condition |= data == fv\n"
     ]
    }
   ],
   "source": [
    "# Add data from FWI\n",
    "fwi = xr.open_mfdataset('../../finalproj_data/time_slice/FWI.GEOS-5.Monthly.Default.201912.nc', combine = 'by_coords')\n",
    "fwi = fwi.drop('time')\n",
    "fwi = fwi.squeeze('time')\n",
    "fwi = fwi['GEOS-5_FWI'].values\n",
    "fwi_shape = list(fwi.shape)\n",
    "fwi_scale_factors = (a/fwi_shape[0], b/fwi_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWI = scale_variable(fwi, fwi_scale_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create latitude and longitude coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106.36052963975135, -46.173405603743404, 157.02551166409236, -4.9856498268633445]\n",
      "[917, 1128]\n"
     ]
    }
   ],
   "source": [
    "bounds = list(fire.bounds) #BoundingBox(left, bottom, right, top)\n",
    "print(bounds)\n",
    "shape = list(fire.shape) #longitude, latitude\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define latitude\n",
    "xlat = np.linspace(bounds[1],bounds[3], shape[0])\n",
    "xlat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define longitude\n",
    "ylon = np.linspace(bounds[0], bounds[2], shape[1])\n",
    "ylon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an xarray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = xr.DataArray(FireMask, [('lat', xlat), ('lon', ylon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = array.to_dataset(name = \"firemask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign(MaxFRP = (('lat', 'lon'), MaxFRP))\n",
    "\n",
    "# Veg bands\n",
    "# ds = ds.assign(EVI = (('lat', 'lon'), EVI))\n",
    "# ds = ds.assign(EVI2 = (('lat', 'lon'), EVI2))\n",
    "# ds = ds.assign(NVDI = (('lat', 'lon'), NVDI))\n",
    "# ds = ds.assign(NIR_reflectance = (('lat', 'lon'), NIR_reflectance))\n",
    "# ds = ds.assign(SWIR1_reflectance = (('lat', 'lon'), SWIR1_reflectance))\n",
    "# ds = ds.assign(SWIR2_reflectance = (('lat', 'lon'), SWIR2_reflectance))\n",
    "# ds = ds.assign(SWIR3_reflectance = (('lat', 'lon'), SWIR3_reflectance))\n",
    "# ds = ds.assign(VI_Quality = (('lat', 'lon'), VI_Quality))\n",
    "# ds = ds.assign(blue_reflectance = (('lat', 'lon'), blue_reflectance))\n",
    "# ds = ds.assign(composite_day_of_the_year = (('lat', 'lon'), composite_day_of_the_year))\n",
    "# ds = ds.assign(green_reflectance = (('lat', 'lon'), green_reflectance))\n",
    "# ds = ds.assign(pixel_reliability = (('lat', 'lon'), pixel_reliability))\n",
    "# ds = ds.assign(red_reflectance = (('lat', 'lon'), red_reflectance))\n",
    "# ds = ds.assign(relative_azimuth_angle = (('lat', 'lon'), relative_azimuth_angle))\n",
    "# ds = ds.assign(sun_zenith_angle = (('lat', 'lon'), sun_zenith_angle))\n",
    "# ds = ds.assign(view_zenith_angle = (('lat', 'lon'), view_zenith_angle))\n",
    "\n",
    "# Precip bands\n",
    "ds = ds.assign(gaugeQualityInfo = (('lat', 'lon'), gaugeQualityInfo))\n",
    "ds = ds.assign(hourlyPrecipRate = (('lat', 'lon'), hourlyPrecipRate))\n",
    "ds = ds.assign(hourlyPrecipRateGC = (('lat', 'lon'), hourlyPrecipRateGC))\n",
    "ds = ds.assign(observationTimeFlag = (('lat', 'lon'), observationTimeFlag))\n",
    "ds = ds.assign(satelliteInfoFlag = (('lat', 'lon'), satelliteInfoFlag))\n",
    "\n",
    "# air bands\n",
    "ds = ds.assign(Albedo_inst = (('lat', 'lon'), Albedo_inst))\n",
    "ds = ds.assign(AvgSurfT_inst = (('lat', 'lon'), CanopInt_inst))\n",
    "ds = ds.assign(CanopInt_inst = (('lat', 'lon'), CanopInt_inst))\n",
    "ds = ds.assign(ECanop_tavg = (('lat', 'lon'), ECanop_tavg))\n",
    "ds = ds.assign(ESoil_tavg = (('lat', 'lon'), ESoil_tavg))\n",
    "ds = ds.assign(Evap_tavg = (('lat', 'lon'), Evap_tavg))\n",
    "ds = ds.assign(LWdown_f_tavg = (('lat', 'lon'), LWdown_f_tavg))\n",
    "ds = ds.assign(Lwnet_tavg = (('lat', 'lon'), Lwnet_tavg))\n",
    "ds = ds.assign(PotEvap_tavg = (('lat', 'lon'), PotEvap_tavg))\n",
    "ds = ds.assign(Psurf_f_inst = (('lat', 'lon'), Psurf_f_inst))\n",
    "ds = ds.assign(Qair_f_inst = (('lat', 'lon'), Qair_f_inst))\n",
    "ds = ds.assign(Qg_tavg = (('lat', 'lon'), Qg_tavg))\n",
    "ds = ds.assign(Qh_tavg = (('lat', 'lon'), Qh_tavg))\n",
    "ds = ds.assign(Qle_tavg = (('lat', 'lon'), Qle_tavg))\n",
    "ds = ds.assign(Qs_acc = (('lat', 'lon'), Qs_acc))\n",
    "ds = ds.assign(Qsb_acc = (('lat', 'lon'), Qsb_acc))\n",
    "ds = ds.assign(Qsm_acc = (('lat', 'lon'), Qsm_acc))\n",
    "ds = ds.assign(Rainf_f_tavg = (('lat', 'lon'), Rainf_f_tavg))\n",
    "ds = ds.assign(RootMoist_inst = (('lat', 'lon'), RootMoist_inst))\n",
    "ds = ds.assign(SWE_inst = (('lat', 'lon'), SWE_inst))\n",
    "ds = ds.assign(SWdown_f_tavg = (('lat', 'lon'), SWdown_f_tavg))\n",
    "ds = ds.assign(SnowDepth_inst = (('lat', 'lon'), SnowDepth_inst))\n",
    "ds = ds.assign(Snowf_tavg = (('lat', 'lon'), Snowf_tavg))\n",
    "ds = ds.assign(SoilMoi100_200cm_inst = (('lat', 'lon'), SoilMoi100_200cm_inst))\n",
    "ds = ds.assign(SoilMoi10_40cm_inst = (('lat', 'lon'), SoilMoi10_40cm_inst))\n",
    "ds = ds.assign(SoilMoi40_100cm_inst = (('lat', 'lon'), SoilMoi40_100cm_inst))\n",
    "ds = ds.assign(SoilTMP0_10cm_inst = (('lat', 'lon'), SoilTMP0_10cm_inst))\n",
    "ds = ds.assign(SoilMoi0_10cm_inst = (('lat', 'lon'), SoilMoi0_10cm_inst))\n",
    "ds = ds.assign(SoilTMP100_200cm_inst = (('lat', 'lon'), SoilTMP100_200cm_inst))\n",
    "ds = ds.assign(SoilTMP10_40cm_inst = (('lat', 'lon'), SoilTMP10_40cm_inst))\n",
    "ds = ds.assign(SoilTMP40_100cm_inst = (('lat', 'lon'), SoilTMP40_100cm_inst))\n",
    "ds = ds.assign(Swnet_tavg = (('lat', 'lon'), Swnet_tavg))\n",
    "ds = ds.assign(Tair_f_inst = (('lat', 'lon'), Tair_f_inst))\n",
    "ds = ds.assign(Tveg_tavg = (('lat', 'lon'), Tveg_tavg))\n",
    "ds = ds.assign(Wind_f_inst = (('lat', 'lon'), Wind_f_inst))\n",
    "\n",
    "# Burned\n",
    "ds = ds.assign(BurnDate = (('lat', 'lon'), BurnDate))\n",
    "ds = ds.assign(Uncertainty = (('lat', 'lon'), Uncertainty))\n",
    "ds = ds.assign(QA = (('lat', 'lon'), QA))\n",
    "ds = ds.assign(FirstDay = (('lat', 'lon'), FirstDay))\n",
    "ds = ds.assign(LastDay = (('lat', 'lon'), LastDay))\n",
    "\n",
    "# FWI\n",
    "ds = ds.assign(FWI = (('lat', 'lon'), FWI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df = ds.to_dataframe()\n",
    "ds_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip lat column\n",
    "ds_df[\"lat\"] = ds_df[\"lat\"].values[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>firemask</th>\n",
       "      <th>MaxFRP</th>\n",
       "      <th>gaugeQualityInfo</th>\n",
       "      <th>hourlyPrecipRate</th>\n",
       "      <th>hourlyPrecipRateGC</th>\n",
       "      <th>observationTimeFlag</th>\n",
       "      <th>satelliteInfoFlag</th>\n",
       "      <th>Albedo_inst</th>\n",
       "      <th>...</th>\n",
       "      <th>Swnet_tavg</th>\n",
       "      <th>Tair_f_inst</th>\n",
       "      <th>Tveg_tavg</th>\n",
       "      <th>Wind_f_inst</th>\n",
       "      <th>BurnDate</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>QA</th>\n",
       "      <th>FirstDay</th>\n",
       "      <th>LastDay</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.98565</td>\n",
       "      <td>106.360530</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.98565</td>\n",
       "      <td>106.405485</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.98565</td>\n",
       "      <td>106.450441</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.98565</td>\n",
       "      <td>106.495396</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.98565</td>\n",
       "      <td>106.540352</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat         lon  firemask  MaxFRP  gaugeQualityInfo  hourlyPrecipRate  \\\n",
       "0 -4.98565  106.360530       3.0     NaN               0.0               0.0   \n",
       "1 -4.98565  106.405485       3.0     NaN               0.0               0.0   \n",
       "2 -4.98565  106.450441       3.0     NaN               0.0               0.0   \n",
       "3 -4.98565  106.495396       3.0     NaN               0.0               0.0   \n",
       "4 -4.98565  106.540352       3.0     NaN               0.0               0.0   \n",
       "\n",
       "   hourlyPrecipRateGC  observationTimeFlag  satelliteInfoFlag  Albedo_inst  \\\n",
       "0               0.415                 -1.0                0.0          NaN   \n",
       "1               0.415                 -1.0                0.0          NaN   \n",
       "2               0.415                 -1.0                0.0          NaN   \n",
       "3               0.415                 -1.0                0.0          NaN   \n",
       "4               0.415                 -1.0                0.0          NaN   \n",
       "\n",
       "   ...  Swnet_tavg  Tair_f_inst  Tveg_tavg  Wind_f_inst  BurnDate  \\\n",
       "0  ...         NaN          NaN        NaN          NaN       NaN   \n",
       "1  ...         NaN          NaN        NaN          NaN       NaN   \n",
       "2  ...         NaN          NaN        NaN          NaN       NaN   \n",
       "3  ...         NaN          NaN        NaN          NaN       NaN   \n",
       "4  ...         NaN          NaN        NaN          NaN       NaN   \n",
       "\n",
       "   Uncertainty   QA  FirstDay  LastDay  FWI  \n",
       "0          NaN  0.0       NaN      NaN  NaN  \n",
       "1          NaN  0.0       NaN      NaN  NaN  \n",
       "2          NaN  0.0       NaN      NaN  NaN  \n",
       "3          NaN  0.0       NaN      NaN  NaN  \n",
       "4          NaN  0.0       NaN      NaN  NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df.to_parquet('../../finalproj_data/ds_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geospatial)",
   "language": "python",
   "name": "merging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
